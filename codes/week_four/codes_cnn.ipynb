{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b32f14",
   "metadata": {},
   "source": [
    "# 制作TFrecord文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f44c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取image和json的id信息\n",
    "image_list = sorted(os.listdir('img/pothole'))\n",
    "json_list = sorted(os.listdir('json/pothole'))\n",
    "print (len(image_list), len(json_list))\n",
    "\n",
    "#判断是不是一一对应\n",
    "image_list_new = []\n",
    "json_list_new = []\n",
    "for i in range(len(image_list)):\n",
    "    a = image_list[i].strip('.jpg')\n",
    "    b = json_list[i].strip('.json')\n",
    "    image_list_new.append(a)\n",
    "    json_list_new.append(b)\n",
    "for i in range(len(image_list_new)):\n",
    "    if image_list_new[i] != json_list_new[i]:\n",
    "        print (image_list_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45427f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "请注意替换下方相对路径，所有路径建议采用ipynb文件的相对路径\n",
    "class_name.txt是全局类型定义文件，需要提前创建，保证与labelme解译的class_name里的病害类型名称一致\n",
    "此处仅制作一个dataset,如果后续研究需要区分训练集、验证集、测试集，请分别制作。\n",
    "'''\n",
    "img_list = sorted(os.listdir('img/pothole'))\n",
    "\n",
    "class_txt = open(\"class_name.txt\",\"r\")\n",
    "class_name = class_txt.read().splitlines()\n",
    "\n",
    "mask_path = 'mask/pothole'\n",
    "\n",
    "for i in range(len(img_list)):\n",
    "    path = \"json_release/pothole/\"+ img_list[i].split(\".\")[0] + \"_json/label.png\"\n",
    "    #rint(path)\n",
    "    mask_id =  img_list[i].split(\".\")[0]\n",
    "    img = Image.open(path)\n",
    "    img_1 = np.array(img)\n",
    "    mask = np.zeros((1024,2048),dtype=int)\n",
    "    with open(\"json_release/pothole/\" + img_list[i].split(\".\")[0] + \"_json/label_names.txt\",\"r\") as f:\n",
    "        names = f.read().splitlines()\n",
    "    for name in names:\n",
    "        # index_json是x_json文件里存在的类label_names.txt，局部类\n",
    "        index_json = names.index(name)\n",
    "        # index_all是全局的类,\n",
    "        index_all = class_name.index(name)\n",
    "        mask[img_1==index_json] = index_all\n",
    "    #lt.imshow(mask*30, cmap='gray', vmin=0, vmax=255)\n",
    "    #lt.show()\n",
    "    cv2.imwrite(os.path.join(mask_path , mask_id+'.png'), mask*30)\n",
    "    #if i==10:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266420e",
   "metadata": {},
   "source": [
    "# 使用TFrecord数据集训练Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47baecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "import io\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11051bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "加在TFrecord的必要函数\n",
    "'''\n",
    "def _parse_data(unparsed_example):\n",
    "    return tf.io.parse_single_example(unparsed_example, image_feature_description)\n",
    "\n",
    "def _bytestring_to_pixels(parsed_example):\n",
    "    byte_string = parsed_example['image']\n",
    "    image = tf.io.decode_image(byte_string)\n",
    "    image = tf.reshape(image,[1024,2048])/255\n",
    "    \n",
    "    mask = tf.io.decode_raw(parsed_example['mask'], tf.uint8)\n",
    "    mask = tf.reshape(mask,[1024,2048])/30#原来的灰度图是label*30的\n",
    "    mask = tf.cast(mask,tf.int32)\n",
    "    mask = tf.one_hot(mask, 7)#转one hot 编码\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "def load_and_extract_images(filepath):\n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    dataset = dataset.map(_parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(_bytestring_to_pixels, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb48d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "载入数据\n",
    "'''\n",
    "image_feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "    \"mask\": tf.io.FixedLenFeature([], tf.string), \n",
    "    }\n",
    "\n",
    "dataset_test = load_and_extract_images(\"pavementscape_test_2048_1024.tfrecords\")\n",
    "dataset_val = load_and_extract_images(\"pavementscape_val_2048_1024.tfrecords\")\n",
    "dataset_train = load_and_extract_images(\"pavementscape_train_2048_1024.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06db083",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "定义IoU损失函数\n",
    "'''\n",
    "\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)  # -1 ultiplied as we want to minimize this value as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cca9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "构建Unet结构\n",
    "请依据自己数据集的图像尺寸情况调整IMG_WIDTH、IMG_HEIGHT、IMG_CHANNELS\n",
    "请依据自己数据集中病害类型调整num_class\n",
    "'''\n",
    "\n",
    "IMG_WIDTH = 2048\n",
    "IMG_HEIGHT = 1024\n",
    "IMG_CHANNELS = 1\n",
    "inputs_pixels = IMG_WIDTH * IMG_HEIGHT\n",
    "num_class=6+1\n",
    "\n",
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "#Contraction path\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "#Expansive path \n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(num_class, (1, 1), activation='sigmoid')(c9)\n",
    "#outputs = tf.argmax(outputs, axis=-1)\n",
    "\n",
    "\n",
    "model_ns = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model_ns.compile(optimizer='adam', loss=[jacard_coef_loss], metrics=[jacard_coef])\n",
    "#model_ns.compile(optimizer='adam', \n",
    "#             loss='CategoricalCrossentropy', #MeanAbsoluteError\n",
    "#             metrics=['accuracy'])\n",
    "model_ns.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5fdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = ''#定义模型参数的保存路径\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath, monitor='val_accuracy', verbose=1,\n",
    "    save_best_only=True, save_weights_only=True,\n",
    "    save_frequency=1)#定义保存模型的节点\n",
    "\n",
    "\n",
    "batch_size=4#Please choose your own batch size based on your GPU menory\n",
    "\n",
    "model_ns.fit(dataset_train.batch(batch_size), epochs=300, verbose=1, shuffle=True, checkpoint_callback)#训练模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
